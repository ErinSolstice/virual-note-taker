{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:19:23.488642Z",
     "start_time": "2021-07-23T04:19:21.854534Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.backends.cudnn as cudnn\n",
    "import yaml\n",
    "from train import train\n",
    "from utils import AttrDict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:19:23.885144Z",
     "start_time": "2021-07-23T04:19:23.880564Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "cudnn.deterministic = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:19:24.119144Z",
     "start_time": "2021-07-23T04:19:24.112032Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_config(file_path):\n",
    "    with open(file_path, 'r', encoding=\"utf8\") as stream:\n",
    "        opt = yaml.safe_load(stream)\n",
    "    opt = AttrDict(opt)\n",
    "    if opt.lang_char == 'None':\n",
    "        characters = ''\n",
    "        for data in opt['select_data'].split('-'):\n",
    "            csv_path = os.path.join(opt['train_data'], data, 'labels.csv')\n",
    "            df = pd.read_csv(csv_path, sep='^([^,]+),', engine='python', usecols=['filename', 'words'], keep_default_na=False)\n",
    "            all_char = ''.join(df['words'])\n",
    "            characters += ''.join(set(all_char))\n",
    "        characters = sorted(set(characters))\n",
    "        opt.character= ''.join(characters)\n",
    "    else:\n",
    "        opt.character = opt.number + opt.symbol + opt.lang_char\n",
    "    os.makedirs(f'./saved_models/{opt.experiment_name}', exist_ok=True)\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T04:49:07.045060Z",
     "start_time": "2021-07-23T04:20:15.050992Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering the images containing characters which are not in opt.character\n",
      "Filtering the images whose label is longer than opt.batch_max_length\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root: all_data\n",
      "opt.select_data: ['wb_train']\n",
      "opt.batch_ratio: ['1']\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    all_data\t dataset: wb_train\n",
      "all_data/wb_train\n",
      "sub-directory:\t/wb_train\t num samples: 3549\n",
      "num total samples of wb_train: 3549 x 1.0 (total_data_usage_ratio) = 3549\n",
      "num samples of wb_train per batch: 32 x 1.0 (batch_ratio) = 32\n",
      "--------------------------------------------------------------------------------\n",
      "Total_batch_size: 32 = 32\n",
      "--------------------------------------------------------------------------------\n",
      "dataset_root:    all_data/wb_val_1\t dataset: /\n",
      "all_data/wb_val_1/\n",
      "sub-directory:\t/.\t num samples: 942\n",
      "--------------------------------------------------------------------------------\n",
      "No Transformation module specified\n",
      "model input parameters 300 300 20 1 256 256 97 34 None VGG BiLSTM CTC\n",
      "Model:\n",
      "DataParallel(\n",
      "  (module): Model(\n",
      "    (FeatureExtraction): VGG_FeatureExtractor(\n",
      "      (ConvNet): Sequential(\n",
      "        (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): ReLU(inplace=True)\n",
      "        (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (4): ReLU(inplace=True)\n",
      "        (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "        (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (7): ReLU(inplace=True)\n",
      "        (8): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (9): ReLU(inplace=True)\n",
      "        (10): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "        (11): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (13): ReLU(inplace=True)\n",
      "        (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (16): ReLU(inplace=True)\n",
      "        (17): MaxPool2d(kernel_size=(2, 1), stride=(2, 1), padding=0, dilation=1, ceil_mode=False)\n",
      "        (18): Conv2d(256, 256, kernel_size=(2, 2), stride=(1, 1))\n",
      "        (19): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (AdaptiveAvgPool): AdaptiveAvgPool2d(output_size=(None, 1))\n",
      "    (SequenceModeling): Sequential(\n",
      "      (0): BidirectionalLSTM(\n",
      "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "      (1): BidirectionalLSTM(\n",
      "        (rnn): LSTM(256, 256, batch_first=True, bidirectional=True)\n",
      "        (linear): Linear(in_features=512, out_features=256, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (Prediction): Linear(in_features=256, out_features=97, bias=True)\n",
      "  )\n",
      ")\n",
      "Modules, Parameters\n",
      "module.FeatureExtraction.ConvNet.0.weight 288\n",
      "module.FeatureExtraction.ConvNet.0.bias 32\n",
      "module.FeatureExtraction.ConvNet.3.weight 18432\n",
      "module.FeatureExtraction.ConvNet.3.bias 64\n",
      "module.FeatureExtraction.ConvNet.6.weight 73728\n",
      "module.FeatureExtraction.ConvNet.6.bias 128\n",
      "module.FeatureExtraction.ConvNet.8.weight 147456\n",
      "module.FeatureExtraction.ConvNet.8.bias 128\n",
      "module.FeatureExtraction.ConvNet.11.weight 294912\n",
      "module.FeatureExtraction.ConvNet.12.weight 256\n",
      "module.FeatureExtraction.ConvNet.12.bias 256\n",
      "module.FeatureExtraction.ConvNet.14.weight 589824\n",
      "module.FeatureExtraction.ConvNet.15.weight 256\n",
      "module.FeatureExtraction.ConvNet.15.bias 256\n",
      "module.FeatureExtraction.ConvNet.18.weight 262144\n",
      "module.FeatureExtraction.ConvNet.18.bias 256\n",
      "module.SequenceModeling.0.rnn.weight_ih_l0 262144\n",
      "module.SequenceModeling.0.rnn.weight_hh_l0 262144\n",
      "module.SequenceModeling.0.rnn.bias_ih_l0 1024\n",
      "module.SequenceModeling.0.rnn.bias_hh_l0 1024\n",
      "module.SequenceModeling.0.rnn.weight_ih_l0_reverse 262144\n",
      "module.SequenceModeling.0.rnn.weight_hh_l0_reverse 262144\n",
      "module.SequenceModeling.0.rnn.bias_ih_l0_reverse 1024\n",
      "module.SequenceModeling.0.rnn.bias_hh_l0_reverse 1024\n",
      "module.SequenceModeling.0.linear.weight 131072\n",
      "module.SequenceModeling.0.linear.bias 256\n",
      "module.SequenceModeling.1.rnn.weight_ih_l0 262144\n",
      "module.SequenceModeling.1.rnn.weight_hh_l0 262144\n",
      "module.SequenceModeling.1.rnn.bias_ih_l0 1024\n",
      "module.SequenceModeling.1.rnn.bias_hh_l0 1024\n",
      "module.SequenceModeling.1.rnn.weight_ih_l0_reverse 262144\n",
      "module.SequenceModeling.1.rnn.weight_hh_l0_reverse 262144\n",
      "module.SequenceModeling.1.rnn.bias_ih_l0_reverse 1024\n",
      "module.SequenceModeling.1.rnn.bias_hh_l0_reverse 1024\n",
      "module.SequenceModeling.1.linear.weight 131072\n",
      "module.SequenceModeling.1.linear.bias 256\n",
      "module.Prediction.weight 24832\n",
      "module.Prediction.bias 97\n",
      "Total Trainable Params: 3781345\n",
      "Trainable params num :  3781345\n",
      "Optimizer:\n",
      "Adadelta (\n",
      "Parameter Group 0\n",
      "    eps: 1e-08\n",
      "    lr: 1.0\n",
      "    rho: 0.95\n",
      "    weight_decay: 0\n",
      ")\n",
      "------------ Options -------------\n",
      "number: 0123456789\n",
      "symbol: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ â‚¬\n",
      "lang_char: ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "experiment_name: wb_only1\n",
      "train_data: all_data\n",
      "valid_data: all_data/wb_val_1\n",
      "manualSeed: 1111\n",
      "workers: 1\n",
      "batch_size: 32\n",
      "num_iter: 300000\n",
      "valInterval: 20000\n",
      "saved_model: \n",
      "FT: False\n",
      "optim: False\n",
      "lr: 1.0\n",
      "beta1: 0.9\n",
      "rho: 0.95\n",
      "eps: 1e-08\n",
      "grad_clip: 5\n",
      "select_data: ['wb_train']\n",
      "batch_ratio: ['1']\n",
      "total_data_usage_ratio: 1.0\n",
      "batch_max_length: 34\n",
      "imgH: 300\n",
      "imgW: 300\n",
      "rgb: False\n",
      "contrast_adjust: 0.0\n",
      "sensitive: True\n",
      "PAD: True\n",
      "data_filtering_off: False\n",
      "Transformation: None\n",
      "FeatureExtraction: VGG\n",
      "SequenceModeling: BiLSTM\n",
      "Prediction: CTC\n",
      "num_fiducial: 20\n",
      "input_channel: 1\n",
      "output_channel: 256\n",
      "hidden_size: 256\n",
      "decode: greedy\n",
      "new_prediction: False\n",
      "freeze_FeatureFxtraction: False\n",
      "freeze_SequenceModeling: False\n",
      "character: 0123456789!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ â‚¬ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "num_class: 97\n",
      "---------------------------------------\n",
      "\n",
      "Iter:  0\n",
      "Iter:  1000\n",
      "Iter:  2000\n",
      "Iter:  3000\n",
      "Iter:  4000\n",
      "Iter:  5000\n",
      "Iter:  6000\n",
      "Iter:  7000\n",
      "Iter:  8000\n",
      "Iter:  9000\n",
      "Iter:  10000\n",
      "Iter:  11000\n",
      "Iter:  12000\n",
      "Iter:  13000\n",
      "Iter:  14000\n",
      "Iter:  15000\n",
      "Iter:  16000\n",
      "Iter:  17000\n",
      "Iter:  18000\n",
      "Iter:  19000\n",
      "Iter:  20000\n",
      "training time:  2971.3169124126434\n",
      "[20000/300000] Train loss: 0.13727, Valid loss: 1.50652, Elapsed_time: 2971.31691\n",
      "Current_accuracy : 5.945, Current_norm_ED  : 0.8314\n",
      "Best_accuracy    : 5.945, Best_norm_ED     : 0.8314\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "that after my talk with   | that afber ay balk ith    | 0.1765\tFalse\n",
      "\"granted personality, and we gave\" | granted pursonality, and we gae\" | 0.4167\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  9.908936500549316\n",
      "Iter:  21000\n",
      "Iter:  22000\n",
      "Iter:  23000\n",
      "Iter:  24000\n",
      "Iter:  25000\n",
      "Iter:  26000\n",
      "Iter:  27000\n",
      "Iter:  28000\n",
      "Iter:  29000\n",
      "Iter:  30000\n",
      "Iter:  31000\n",
      "Iter:  32000\n",
      "Iter:  33000\n",
      "Iter:  34000\n",
      "Iter:  35000\n",
      "Iter:  36000\n",
      "Iter:  37000\n",
      "Iter:  38000\n",
      "Iter:  39000\n",
      "Iter:  40000\n",
      "training time:  2969.2661752700806\n",
      "[40000/300000] Train loss: 0.00003, Valid loss: 1.61609, Elapsed_time: 5950.49202\n",
      "Current_accuracy : 5.839, Current_norm_ED  : 0.8308\n",
      "Best_accuracy    : 5.945, Best_norm_ED     : 0.8314\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "a moment. Her hair was    | a malment. Her hair has   | 0.4527\tFalse\n",
      "&quot;Soon we must fight.&quot; | &quo;ocon we must fight.&quot; | 0.1069\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  9.856743097305298\n",
      "Iter:  41000\n",
      "Iter:  42000\n",
      "Iter:  43000\n",
      "Iter:  44000\n",
      "Iter:  45000\n",
      "Iter:  46000\n",
      "Iter:  47000\n",
      "Iter:  48000\n",
      "Iter:  49000\n",
      "Iter:  50000\n",
      "Iter:  51000\n",
      "Iter:  52000\n",
      "Iter:  53000\n",
      "Iter:  54000\n",
      "Iter:  55000\n",
      "Iter:  56000\n",
      "Iter:  57000\n",
      "Iter:  58000\n",
      "Iter:  59000\n",
      "Iter:  60000\n",
      "training time:  2934.5696654319763\n",
      "[60000/300000] Train loss: 0.00002, Valid loss: 1.68475, Elapsed_time: 8894.91843\n",
      "Current_accuracy : 6.157, Current_norm_ED  : 0.8305\n",
      "Best_accuracy    : 6.157, Best_norm_ED     : 0.8314\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "Eichmann mind. Eichmann   | Eich onam mind. Eichonamm | 0.0424\tFalse\n",
      "But for some reason we actively | But for sope reason we artinly | 0.1646\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  9.628038167953491\n",
      "Iter:  61000\n",
      "Iter:  62000\n",
      "Iter:  63000\n",
      "Iter:  64000\n",
      "Iter:  65000\n",
      "Iter:  66000\n",
      "Iter:  67000\n",
      "Iter:  68000\n",
      "Iter:  69000\n",
      "Iter:  70000\n",
      "Iter:  71000\n",
      "Iter:  72000\n",
      "Iter:  73000\n",
      "Iter:  74000\n",
      "Iter:  75000\n",
      "Iter:  76000\n",
      "Iter:  77000\n",
      "Iter:  78000\n",
      "Iter:  79000\n",
      "Iter:  80000\n",
      "training time:  2909.0001730918884\n",
      "[80000/300000] Train loss: 0.00001, Valid loss: 1.72941, Elapsed_time: 11813.54664\n",
      "Current_accuracy : 5.732, Current_norm_ED  : 0.8302\n",
      "Best_accuracy    : 6.157, Best_norm_ED     : 0.8314\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "to the President and      | Eo the President and      | 0.4549\tFalse\n",
      "Mary&apos;s inspection.   | Masg aps inspetion.       | 0.0625\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  9.42374873161316\n",
      "Iter:  81000\n",
      "Iter:  82000\n",
      "Iter:  83000\n",
      "Iter:  84000\n",
      "Iter:  85000\n",
      "Iter:  86000\n",
      "Iter:  87000\n",
      "Iter:  88000\n",
      "Iter:  89000\n",
      "Iter:  90000\n",
      "Iter:  91000\n",
      "Iter:  92000\n",
      "Iter:  93000\n",
      "Iter:  94000\n",
      "Iter:  95000\n",
      "Iter:  96000\n",
      "Iter:  97000\n",
      "Iter:  98000\n",
      "Iter:  99000\n",
      "Iter:  100000\n",
      "training time:  2910.8417840003967\n",
      "[100000/300000] Train loss: 0.00001, Valid loss: 1.76302, Elapsed_time: 14733.81218\n",
      "Current_accuracy : 5.732, Current_norm_ED  : 0.8295\n",
      "Best_accuracy    : 6.157, Best_norm_ED     : 0.8314\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "He said bluntly in        | e sald bluatly in         | 0.2544\tFalse\n",
      "a grey pleated skirt and  | a grey pleated stirt and  | 0.2367\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  9.41344404220581\n",
      "Iter:  101000\n",
      "Iter:  102000\n",
      "Iter:  103000\n",
      "Iter:  104000\n",
      "Iter:  105000\n",
      "Iter:  106000\n",
      "Iter:  107000\n",
      "Iter:  108000\n",
      "Iter:  109000\n",
      "Iter:  110000\n",
      "Iter:  111000\n",
      "Iter:  112000\n",
      "Iter:  113000\n",
      "Iter:  114000\n",
      "Iter:  115000\n",
      "Iter:  116000\n",
      "Iter:  117000\n",
      "Iter:  118000\n",
      "Iter:  119000\n",
      "Iter:  120000\n",
      "training time:  2910.700151205063\n",
      "[120000/300000] Train loss: 0.00001, Valid loss: 1.82381, Elapsed_time: 17653.92577\n",
      "Current_accuracy : 5.732, Current_norm_ED  : 0.8298\n",
      "Best_accuracy    : 6.157, Best_norm_ED     : 0.8314\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "the atoning efficacy of the | the atoning efficacy of the | 0.7167\tTrue\n",
      "at once dispelled her fears. | \"at once dispelled her feas. | 0.2789\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  9.560970306396484\n",
      "Iter:  121000\n",
      "Iter:  122000\n",
      "Iter:  123000\n",
      "Iter:  124000\n",
      "Iter:  125000\n",
      "Iter:  126000\n",
      "Iter:  127000\n",
      "Iter:  128000\n",
      "Iter:  129000\n",
      "Iter:  130000\n",
      "Iter:  131000\n",
      "Iter:  132000\n",
      "Iter:  133000\n",
      "Iter:  134000\n",
      "Iter:  135000\n",
      "Iter:  136000\n",
      "Iter:  137000\n",
      "Iter:  138000\n",
      "Iter:  139000\n",
      "Iter:  140000\n",
      "training time:  2914.6346337795258\n",
      "[140000/300000] Train loss: 0.00000, Valid loss: 1.79733, Elapsed_time: 20578.12238\n",
      "Current_accuracy : 5.839, Current_norm_ED  : 0.8302\n",
      "Best_accuracy    : 6.157, Best_norm_ED     : 0.8314\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "\"co-operated, we made the little\" | co- opercated, we made the litte\" | 0.1239\tFalse\n",
      "earth stop her from talking. | \"eaurtd stop her from taking. | 0.1786\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  9.528185844421387\n",
      "Iter:  141000\n",
      "Iter:  142000\n",
      "Iter:  143000\n",
      "Iter:  144000\n",
      "Iter:  145000\n",
      "Iter:  146000\n",
      "Iter:  147000\n",
      "Iter:  148000\n",
      "Iter:  149000\n",
      "Iter:  150000\n",
      "Iter:  151000\n",
      "Iter:  152000\n",
      "Iter:  153000\n",
      "Iter:  154000\n",
      "Iter:  155000\n",
      "Iter:  156000\n",
      "Iter:  157000\n",
      "Iter:  158000\n",
      "Iter:  159000\n",
      "Iter:  160000\n",
      "training time:  2916.634535551071\n",
      "[160000/300000] Train loss: 0.00000, Valid loss: 1.82793, Elapsed_time: 23504.28510\n",
      "Current_accuracy : 5.732, Current_norm_ED  : 0.8300\n",
      "Best_accuracy    : 6.157, Best_norm_ED     : 0.8314\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "and the ghost became a    | and the ghost became a    | 0.2678\tTrue\n",
      "\"produced to exacting standards,\" | pordued thor akartoy sFalads,\" | 0.0017\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  9.681318521499634\n",
      "Iter:  161000\n",
      "Iter:  162000\n",
      "Iter:  163000\n",
      "Iter:  164000\n",
      "Iter:  165000\n",
      "Iter:  166000\n",
      "Iter:  167000\n",
      "Iter:  168000\n",
      "Iter:  169000\n",
      "Iter:  170000\n",
      "Iter:  171000\n",
      "Iter:  172000\n",
      "Iter:  173000\n",
      "Iter:  174000\n",
      "Iter:  175000\n",
      "Iter:  176000\n",
      "Iter:  177000\n",
      "Iter:  178000\n",
      "Iter:  179000\n",
      "Iter:  180000\n",
      "training time:  2914.924777507782\n",
      "[180000/300000] Train loss: 0.00000, Valid loss: 1.87882, Elapsed_time: 26428.89219\n",
      "Current_accuracy : 5.839, Current_norm_ED  : 0.8299\n",
      "Best_accuracy    : 6.157, Best_norm_ED     : 0.8314\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "John nodded - he could    | John nodded a he conld    | 0.0388\tFalse\n",
      "\"the worst in women, as they\" | Hhe wanst i women, as thley\" | 0.1325\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  9.90813398361206\n",
      "Iter:  181000\n",
      "Iter:  182000\n",
      "Iter:  183000\n",
      "Iter:  184000\n",
      "Iter:  185000\n",
      "Iter:  186000\n",
      "Iter:  187000\n",
      "Iter:  188000\n",
      "Iter:  189000\n",
      "Iter:  190000\n",
      "Iter:  191000\n",
      "Iter:  192000\n",
      "Iter:  193000\n",
      "Iter:  194000\n",
      "Iter:  195000\n",
      "Iter:  196000\n",
      "Iter:  197000\n",
      "Iter:  198000\n",
      "Iter:  199000\n",
      "Iter:  200000\n",
      "training time:  2988.6101751327515\n",
      "[200000/300000] Train loss: 0.00000, Valid loss: 1.84946, Elapsed_time: 29427.41050\n",
      "Current_accuracy : 5.732, Current_norm_ED  : 0.8295\n",
      "Best_accuracy    : 6.157, Best_norm_ED     : 0.8314\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "\"gifts for the high Altar, and\" | gifts of the nign Nrer, and\" | 0.2108\tFalse\n",
      "understanding of this verse is | understanding of his verse is | 0.3536\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  10.192495584487915\n",
      "Iter:  201000\n",
      "Iter:  202000\n",
      "Iter:  203000\n",
      "Iter:  204000\n",
      "Iter:  205000\n",
      "Iter:  206000\n",
      "Iter:  207000\n",
      "Iter:  208000\n",
      "Iter:  209000\n",
      "Iter:  210000\n",
      "Iter:  211000\n",
      "Iter:  212000\n",
      "Iter:  213000\n",
      "Iter:  214000\n",
      "Iter:  215000\n",
      "Iter:  216000\n",
      "Iter:  217000\n",
      "Iter:  218000\n",
      "Iter:  219000\n",
      "Iter:  220000\n",
      "training time:  3050.3651583194733\n",
      "[220000/300000] Train loss: 0.00000, Valid loss: 1.88628, Elapsed_time: 32487.96816\n",
      "Current_accuracy : 5.839, Current_norm_ED  : 0.8295\n",
      "Best_accuracy    : 6.157, Best_norm_ED     : 0.8314\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "M P. Has de Gaulle lost his grip? | Mif. Has de bande lost his grip? | 0.1048\tFalse\n",
      "basic tools - probably a  | basie toals - probaily a  | 0.2285\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  10.167481422424316\n",
      "Iter:  221000\n",
      "Iter:  222000\n",
      "Iter:  223000\n",
      "Iter:  224000\n",
      "Iter:  225000\n",
      "Iter:  226000\n",
      "Iter:  227000\n",
      "Iter:  228000\n",
      "Iter:  229000\n",
      "Iter:  230000\n",
      "Iter:  231000\n",
      "Iter:  232000\n",
      "Iter:  233000\n",
      "Iter:  234000\n",
      "Iter:  235000\n",
      "Iter:  236000\n",
      "Iter:  237000\n",
      "Iter:  238000\n",
      "Iter:  239000\n",
      "Iter:  240000\n",
      "training time:  3034.031617164612\n",
      "[240000/300000] Train loss: 0.00000, Valid loss: 1.89633, Elapsed_time: 35532.16726\n",
      "Current_accuracy : 5.732, Current_norm_ED  : 0.8294\n",
      "Best_accuracy    : 6.157, Best_norm_ED     : 0.8314\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "Leisured mischief-        | Leisured rschuef-         | 0.2456\tFalse\n",
      "drained of colour. She    | wrained af colanr. She    | 0.4037\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  10.694509744644165\n",
      "Iter:  241000\n",
      "Iter:  242000\n",
      "Iter:  243000\n",
      "Iter:  244000\n",
      "Iter:  245000\n",
      "Iter:  246000\n",
      "Iter:  247000\n",
      "Iter:  248000\n",
      "Iter:  249000\n",
      "Iter:  250000\n",
      "Iter:  251000\n",
      "Iter:  252000\n",
      "Iter:  253000\n",
      "Iter:  254000\n",
      "Iter:  255000\n",
      "Iter:  256000\n",
      "Iter:  257000\n",
      "Iter:  258000\n",
      "Iter:  259000\n",
      "Iter:  260000\n",
      "training time:  3009.4382271766663\n",
      "[260000/300000] Train loss: 0.00000, Valid loss: 1.88964, Elapsed_time: 38552.29999\n",
      "Current_accuracy : 5.626, Current_norm_ED  : 0.8299\n",
      "Best_accuracy    : 6.157, Best_norm_ED     : 0.8314\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "\"when I read, bespectacled. The\" | when I read, hespestacled. The\" | 0.1777\tFalse\n",
      "The trench remained       | The treneh remsined       | 0.6994\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  10.859806060791016\n",
      "Iter:  261000\n",
      "Iter:  262000\n",
      "Iter:  263000\n",
      "Iter:  264000\n",
      "Iter:  265000\n",
      "Iter:  266000\n",
      "Iter:  267000\n",
      "Iter:  268000\n",
      "Iter:  269000\n",
      "Iter:  270000\n",
      "Iter:  271000\n",
      "Iter:  272000\n",
      "Iter:  273000\n",
      "Iter:  274000\n",
      "Iter:  275000\n",
      "Iter:  276000\n",
      "Iter:  277000\n",
      "Iter:  278000\n",
      "Iter:  279000\n",
      "Iter:  280000\n",
      "training time:  3061.2920928001404\n",
      "[280000/300000] Train loss: 0.00000, Valid loss: 1.92335, Elapsed_time: 41624.45289\n",
      "Current_accuracy : 5.626, Current_norm_ED  : 0.8297\n",
      "Best_accuracy    : 6.157, Best_norm_ED     : 0.8314\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "Even the snow-capped      | ewen the snowt capped     | 0.1938\tFalse\n",
      "objectives.               | olrgectives.              | 0.3175\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  11.099488496780396\n",
      "Iter:  281000\n",
      "Iter:  282000\n",
      "Iter:  283000\n",
      "Iter:  284000\n",
      "Iter:  285000\n",
      "Iter:  286000\n",
      "Iter:  287000\n",
      "Iter:  288000\n",
      "Iter:  289000\n",
      "Iter:  290000\n",
      "Iter:  291000\n",
      "Iter:  292000\n",
      "Iter:  293000\n",
      "Iter:  294000\n",
      "Iter:  295000\n",
      "Iter:  296000\n",
      "Iter:  297000\n",
      "Iter:  298000\n",
      "Iter:  299000\n",
      "Iter:  300000\n",
      "training time:  3091.9499995708466\n",
      "[300000/300000] Train loss: 0.00000, Valid loss: 1.91157, Elapsed_time: 44727.50238\n",
      "Current_accuracy : 5.732, Current_norm_ED  : 0.8295\n",
      "Best_accuracy    : 6.157, Best_norm_ED     : 0.8314\n",
      "--------------------------------------------------------------------------------\n",
      "Ground Truth              | Prediction                | Confidence Score & T/F\n",
      "--------------------------------------------------------------------------------\n",
      "the nuclei increase in size | tenucleir increase in size | 0.5092\tFalse\n",
      "Like most supremely powerful | Lile most supramely pomerthl | 0.2384\tFalse\n",
      "--------------------------------------------------------------------------------\n",
      "validation time:  12.105714797973633\n",
      "end the training\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001B[1;31mSystemExit\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jones\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3452: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "opt = get_config(\"config_files/wb_val-1_config.yaml\")\n",
    "train(opt, amp=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    }
   ],
   "source": [
    "%tb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}